name: Test Notebooks

on:
  push:
    branches: [main, master]
    paths:
      - '**/*.py'
      - '**/*.ipynb'
      - '.github/workflows/test_notebooks.yml'
  pull_request:
    branches: [main, master]
    paths:
      - '**/*.py'
      - '**/*.ipynb'
      - '.github/workflows/test_notebooks.yml'
  workflow_dispatch:  # Allows manual triggering

jobs:
  test:
    strategy:
      matrix:
        include:
          - os: ubuntu-latest
            os_name: linux
          - os: macos-latest
            os_name: macos
          - os: windows-latest
            os_name: windows
    runs-on: ${{ matrix.os }}
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install System Dependencies (Linux)
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update
          sudo apt-get install -y graphviz

      - name: Install System Dependencies (macOS)
        if: matrix.os == 'macos-latest'
        run: brew install graphviz

      - name: Install System Dependencies (Windows)
        if: matrix.os == 'windows-latest'
        run: choco install graphviz

      - name: Setup Data and Paths
        shell: bash
        run: |
          # Logging for debug
          echo "GITHUB_WORKSPACE: ${{ github.workspace }}"
          echo "RUNNER_WORKSPACE: ${{ runner.workspace }}"
          
          # 1. Download and extract in the current workspace
          curl -sL "https://files.osf.io/v1/resources/3u5em/providers/osfstorage/?zip=" -o data.zip
          unzip -q data.zip && unzip -q da_data_repo.zip
          
          # 2. Determine target directory
          # The notebooks use: dirname = current_path.split("da_case_studies")[0]
          # This means da_data_repo must be a sibling to the FIRST occurrence of 'da_case_studies'
          # On GHA: github.workspace = /home/runner/work/REPO/REPO (Unix) or D:\a\REPO\REPO (Windows)
          # So first 'da_case_studies' parent = /home/runner/work/ or D:\a\
          # runner.workspace = /home/runner/work/REPO or D:\a\REPO
          # dirname(runner.workspace) gives us the correct location
          
          # Convert backslashes to forward slashes for bash compatibility on Windows
          RUNNER_WS=$(echo "${{ runner.workspace }}" | sed 's|\\|/|g')
          TARGET_ROOT=$(dirname "$RUNNER_WS")
          echo "TARGET_ROOT: $TARGET_ROOT"
          
          # 3. Move to the target directory
          rm -rf "$TARGET_ROOT/da_data_repo"
          mv da_data_repo "$TARGET_ROOT/"
          
          # 4. Cleanup
          rm data.zip da_data_repo.zip
          rm -rf __MACOSX
          
          # 5. Symlinks (Unix only, notebooks use absolute paths so not strictly required)
          if [ "${{ matrix.os_name }}" != "windows" ]; then
            cd ..
            ln -s da_case_studies/ch* . || true
            ln -s da_case_studies/da* . || true
            ln -s da_case_studies/pre* . || true
          fi

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-variant: Miniforge3
          miniforge-version: latest
          activate-environment: daenv
          environment-file: ch00-tech-prep/daenv_${{ matrix.os_name }}.yml
          python-version: "3.12"
          auto-activate-base: false

      - name: Run notebook tests
        shell: bash -el {0}
        env:
          MPLBACKEND: Agg
        run: |
          python ch00-tech-prep/test_env.py

      - name: Upload test artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failed-test-outputs-${{ matrix.os_name }}
          path: |
            **/*.log
          retention-days: 7
