name: Test Notebooks

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:  # Allows manual triggering

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # Extended timeout for notebook execution + data download

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download data from OSF.io
        run: |
          # Create the data directory at the same level as da_case_studies
          cd ..
          
          # Download the complete dataset zip from OSF.io using correct URL format
          echo "Downloading datasets from OSF.io..."
          curl -L "https://files.osf.io/v1/resources/3u5em/providers/osfstorage/?zip=" -o project_3u5em.zip
          
          # Check if download succeeded
          file project_3u5em.zip
          ls -la project_3u5em.zip
          
          # Extract the data
          echo "Extracting data..."
          unzip -q project_3u5em.zip
          
          # Clean up zip file
          rm project_3u5em.zip
          
          # List what was extracted to verify structure
          echo "Extracted contents:"
          ls -la
          
          # Find and ensure the data folder is named da_data_repo
          # Check common patterns that might be used
          if [ -d "da_data_repo" ]; then
            echo "da_data_repo folder found"
          elif [ -d "clean" ]; then
            # If extracted directly as 'clean' folder, wrap it
            mkdir -p da_data_repo
            mv clean/* da_data_repo/
            echo "Moved clean/ contents to da_data_repo/"
          else
            # List all directories and try to find the data
            echo "Looking for data directories..."
            find . -maxdepth 2 -type d -name "clean" 2>/dev/null || true
            # If there's a single top-level directory (common zip pattern), use it
            dir_count=$(find . -maxdepth 1 -mindepth 1 -type d | wc -l)
            if [ "$dir_count" -eq 1 ]; then
              extracted_dir=$(find . -maxdepth 1 -mindepth 1 -type d)
              if [ "$extracted_dir" != "./da_data_repo" ]; then
                mv "$extracted_dir" da_data_repo
                echo "Renamed $extracted_dir to da_data_repo"
              fi
            fi
          fi
          
          echo "Final da_data_repo structure:"
          ls -la da_data_repo/ 2>/dev/null || echo "Warning: da_data_repo not found - listing all:"
          ls -la

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-variant: Miniforge3
          miniforge-version: latest
          activate-environment: daenv
          environment-file: ch00-tech-prep/daenv_linux.yml
          python-version: "3.12"
          auto-activate-base: false

      - name: Display environment info
        shell: bash -el {0}
        run: |
          conda info
          python --version

      - name: Install CmdStan (required for Prophet)
        shell: bash -el {0}
        run: |
          python -c "import cmdstanpy; cmdstanpy.install_cmdstan()"

      - name: Run notebook tests
        shell: bash -el {0}
        env:
          MPLBACKEND: Agg
        run: |
          python ch00-tech-prep/test_env.py

      - name: Upload test artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failed-test-outputs
          path: |
            **/*.py
            !ch00-tech-prep/test_env.py
          retention-days: 7
