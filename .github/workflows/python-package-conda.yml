name: Test Notebooks

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:  # Allows manual triggering

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # Extended timeout for notebook execution + data download

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download data from OSF.io
        run: |
          # DEBUG: Print current location and structure
          echo "Current directory: $(pwd)"
          echo "Workspace root: $GITHUB_WORKSPACE"
          
          # Target directory expected by notebooks: /home/runner/work/da_data_repo
          # We'll construct this absolute path to be safe
          TARGET_DATA_DIR="/home/runner/work/da_data_repo"
          
          # Go to parent directory (workspace root)
          cd .. 
          
          # Create a specific directory for the download to avoid conflicts
          mkdir -p raw_data_download
          cd raw_data_download
          
          # Download the dataset
          echo "Downloading datasets from OSF.io..."
          curl -L "https://files.osf.io/v1/resources/3u5em/providers/osfstorage/?zip=" -o project_3u5em.zip
          
          # Extract
          echo "Extracting data..."
          unzip -q project_3u5em.zip
          rm project_3u5em.zip
          
          # Move data to the absolute target directory
          echo "Moving data to $TARGET_DATA_DIR ..."
          
          # Check for nested zip (common OSF pattern)
          if [ -f "da_data_repo.zip" ]; then
             echo "Found nested zip: da_data_repo.zip - extracting..."
             unzip -q da_data_repo.zip
             rm da_data_repo.zip
          fi
          
          # Count items in the download dir
          dir_count=$(find . -maxdepth 1 -mindepth 1 -type d | wc -l)
          file_count=$(find . -maxdepth 1 -mindepth 1 -type f | wc -l)
          
          if [ "$dir_count" -eq 1 ] && [ "$file_count" -eq 0 ]; then
            # Case: Zip contained a single folder wrapping the data
            single_dir=$(find . -maxdepth 1 -mindepth 1 -type d)
            echo "Found single wrapper folder: $single_dir"
            mv "$single_dir" "$TARGET_DATA_DIR"
          else
            # Case: Zip contained loose files/folders
            echo "Found loose files/folders, moving current dir content"
            # Move the content of the current dir to the target
            mkdir -p "$TARGET_DATA_DIR"
            mv * "$TARGET_DATA_DIR/"
          fi
          
          echo "Data directory contents:"
          ls -la "$TARGET_DATA_DIR"
          
          echo "DEBUG: Listing full structure of /home/runner/work/"
          find /home/runner/work -maxdepth 3 -type d

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-variant: Miniforge3
          miniforge-version: latest
          activate-environment: daenv
          environment-file: ch00-tech-prep/daenv_linux.yml
          python-version: "3.12"
          auto-activate-base: false

      - name: Display environment info
        shell: bash -el {0}
        run: |
          conda info
          python --version

      #- name: Install CmdStan (required for Prophet)
      #  shell: bash -el {0}
      #  run: |
      #    python -c "import cmdstanpy; cmdstanpy.install_cmdstan()"

      - name: Run notebook tests
        shell: bash -el {0}
        env:
          MPLBACKEND: Agg
        run: |
          python ch00-tech-prep/test_env.py

      - name: Upload test artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failed-test-outputs
          path: |
            **/*.py
            !ch00-tech-prep/test_env.py
          retention-days: 7
